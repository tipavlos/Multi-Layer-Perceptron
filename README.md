# Multi-Layer-Perceptron
Language C++

Optimizer : Gradient Descent \n
Activation functions : linear,relu,sigmoid,tanh \n
Batch training supported. \n
Selection of the number of hidden layers and number of neurons per layer supported.
