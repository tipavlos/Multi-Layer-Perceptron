# Multi-Layer-Perceptron
Language C++

Optimizer : Gradient Descent
Activation functions : linear,relu,sigmoid,tanh
Batch training supported.
Selection of the number of hidden layers and number of neurons per layer supported.
